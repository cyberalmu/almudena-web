---
title: "El 68% de mis estudiantes cambió cómo usa ChatGPT. Así lo conseguí."
subtitle: "Una intervención breve de alfabetización crítica en IA (y por qué funciona)."
date: 2025-12-01
image: /img/Newsletter011225_portada.png
tags:
  - Pedagogía
  - IA en educación
  - Metodología
  - Evaluación
readingTime: 8
linkedinUrl: "https://www.linkedin.com/pulse/el-68-de-mis-estudiantes-cambió-cómo-usa-chatgpt-así-lo-almudena-diaz-tm3uf/"
---

El curso pasado tomé una decisión arriesgada en mi asignatura de comunicación profesional: en vez de prohibir ChatGPT, dediqué varias sesiones a enseñar a usarlo bien.

La pregunta era sencilla: **¿cambiará realmente la forma en que los estudiantes usan IA si les enseñamos a usarla con criterio?**

Al final del cuatrimestre hice una encuesta.

> **El 68,4% reconoció que había cambiado completamente su forma de usar IA.**  
> No "un poco". Completamente.

Este porcentaje es extraordinariamente alto para una intervención tan breve. No indica un cambio superficial, sino un **giro conceptual** en cómo entienden y usan estas herramientas.

## Por qué era necesario hacer esto

La irrupción de los modelos generativos ha cambiado radicalmente el ecosistema universitario. Mientras muchas instituciones optan por prohibir su uso o limitarlo a "casos controlados", la evidencia reciente apunta a otra dirección: **la clave no es evitar la IA, sino enseñar a usarla bien**.

Los estudios muestran que el uso acrítico de IA deteriora procesos esenciales como:

- la argumentación
- la búsqueda de fuentes fiables
- la estructuración del pensamiento

Pero también muestran que una intervención pedagógica bien diseñada **reduce la dependencia** y **mejora la calidad del aprendizaje**.

Con este marco en mente, diseñé una intervención explícita de **alfabetización crítica en IA generativa** para mi asignatura.

## Qué hice exactamente

La intervención no fue compleja. Consistió en actividades distribuidas a lo largo de varias sesiones:

### 1) Análisis comparado de textos

Comparamos textos generados por ChatGPT con textos escritos por humanos. Evaluamos:

- coherencia
- adecuación al registro
- calidad de los argumentos

Los estudiantes aprendieron a identificar el **"tono IA"**: genérico, excesivamente neutro, sin voz propia.

### 2) Detección de errores y sesgos

Buscamos:

- referencias inventadas
- incoherencias temporales o causales
- "alucinaciones" del modelo

Descubrieron que ChatGPT puede sonar muy seguro mientras dice algo completamente falso.

### 3) Uso de IA como andamiaje, no como autor

Practicamos:

- reformulación
- mejora de estilo
- detección de ambigüedades

Discutimos cuándo la IA debe entrar en el proceso de escritura y cuándo no. La clave:

> **la IA como apoyo para pensar, no como sustituto del pensamiento.**

### 4) Prácticas reales

Trabajamos con tareas auténticas:

- correos electrónicos académicos
- microensayos
- pequeñas tareas escritas

En todas ellas, la IA solo podía utilizarse como **apoyo controlado**. No prohibí su uso. **Exigí que lo usaran bien.**

## Qué cambió en los estudiantes

Los resultados de la encuesta fueron reveladores.

### Antes de la intervención

- Copiaban textos generados sin revisar.
- Pedían a ChatGPT que "escribiera el correo por ellos" sin entender el género textual.
- Consideraban la IA como una fuente de información fiable *per se*.
- No detectaban errores ni verificaban información.

### Después de la intervención

- Revisan y editan críticamente cada *output*.
- Utilizan la IA como apoyo para estructurar ideas, no como autora del mensaje.
- Verifican fuentes y comprueban el razonamiento interno del texto.
- Reconocen errores y sesgos de la herramienta.
- Entienden cuándo usar IA y cuándo no.

Este cambio se alinea con lo que los estudios recientes sugieren: si se entrena explícitamente la detección de limitaciones del modelo, **disminuye la dependencia** y **aumenta la calidad del pensamiento autónomo**.

## La IA enmascara carencias básicas

Al analizar los ejercicios escritos y, sobre todo, los correos electrónicos, emergió un patrón preocupante que no había anticipado.

**La IA estaba ocultando déficits de alfabetización académica básica.**

Muchos estudiantes no dominaban todavía:

- la estructura mínima de un correo formal
- el registro académico adecuado
- la puntuación asociada a saludos y cierres (muchos no sabían que van dos puntos después del saludo)
- la adecuación discursiva al contexto comunicativo

ChatGPT generaba correos "correctos", lo que permitía a los estudiantes parecer competentes sin serlo realmente.

Esta conclusión es pedagógicamente muy relevante:

> **la IA no sustituye competencias que no existen; las encubre.**

Y solo si hacemos explícito ese proceso podemos trabajar esas competencias de forma efectiva.

La intervención, por tanto, no solo mejoró el uso de IA, sino también la propia competencia comunicativa de los estudiantes. Al entender qué hacía ChatGPT, entendieron mejor qué deberían hacer ellos.

## Lo que me sorprendió más: todos querían aprender más

Uno de los resultados más reveladores de la encuesta fue este:

> **El 100% del alumnado pidió más formación específica sobre uso de IA.**

Nadie afirmó que "ya sabía usarla". Nadie consideró la formación innecesaria. Todos pidieron más clases sobre esto.

Esto desmonta dos mitos que escucho constantemente en pasillos y claustros.

### Mito 1: "Los jóvenes ya saben usar IA"

No. Saben generar texto. **No saben evaluarlo.**

Saben pedirle a ChatGPT que escriba algo. No saben detectar cuándo lo que escribió es incorrecto, sesgado o irrelevante. Confunden familiaridad tecnológica con alfabetización crítica.

### Mito 2: "A los estudiantes no les interesa aprender esto"

Les interesa, y mucho, si la formación es rigurosa, práctica y útil.

No quieren sermones sobre "los peligros de la IA". Quieren herramientas concretas para usarla bien. Y cuando se las das, responden.

## Qué significa esto para la docencia universitaria

Esta intervención confirma algo que la investigación internacional ya señala:

> **La alfabetización crítica en IA no es opcional. Es imprescindible.**

Porque la IA modifica la relación del estudiante con el texto, altera la forma de planificar tareas, cambia la percepción de la autoridad de las fuentes y facilita atajos cognitivos que pueden debilitar aprendizajes profundos.

Pero también porque, bien usada, potencia el pensamiento crítico, mejora la autorregulación, eleva la calidad del trabajo escrito y reduce la ansiedad ante tareas complejas.

La cuestión no es "IA sí o IA no".

La cuestión es:

> **¿estamos enseñando a usarla con criterio?**

Porque si no la enseñamos, los estudiantes la usarán de todas formas. Pero la usarán mal.

## Mi conclusión

Tras esta intervención, mi conclusión es clara:

> **Si no enseñamos IA, el alumnado la utilizará mal. Si la enseñamos bien, la usará para pensar mejor.**

La alfabetización crítica en IA generativa debe incorporarse a cualquier currículo universitario. No como un accesorio tecnológico, sino como parte del desarrollo de competencias esenciales:

- análisis
- argumentación
- evaluación de fuentes
- pensamiento crítico
- comunicación efectiva

El reto es grande. La oportunidad, también.

Y los datos muestran que funciona.

Próximamente se publicará el artículo académico completo sobre esta innovación docente, con la metodología detallada, los resultados completos del estudio y las implicaciones pedagógicas. Os mantendré informados.

---

**¿Has implementado algo similar en tus clases? ¿Qué estrategias estás usando para integrar IA de forma crítica en tu docencia?**

Me encantaría conocer otras experiencias y aprender de ellas.